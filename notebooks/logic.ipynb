{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fetching talks from: https://www.ted.com/talks?page=1\n",
      "WARNING:root:No talk links found with the given selector. Check page structure.\n",
      "INFO:root:Found 0 talk URLs\n",
      "INFO:root:Sample talk URLs: []\n",
      "INFO:root:Processed 0 opening lines\n",
      "INFO:root:Sample results: []\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import logging\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "# Set up basic logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "class TEDTalkScraper:\n",
    "    \"\"\"\n",
    "    Responsible for scraping TED talk URLs and extracting the opening line\n",
    "    from the transcript page.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.base_url = \"https://www.ted.com\"\n",
    "        self.talks_url = self.base_url + \"/talks\"\n",
    "    \n",
    "    def get_talk_urls(self, num_pages=1):\n",
    "        \"\"\"\n",
    "        Fetch talk URLs from TED talks listing pages.\n",
    "        \"\"\"\n",
    "        talk_urls = []\n",
    "        for page in range(1, num_pages+1):\n",
    "            url = f\"{self.talks_url}?page={page}\"\n",
    "            logging.info(f\"Fetching talks from: {url}\")\n",
    "            response = requests.get(url)\n",
    "            if response.status_code != 200:\n",
    "                logging.error(f\"Failed to fetch page {page}\")\n",
    "                continue\n",
    "            \n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            # Example approach: select anchors with href^=\"/talks/\" and data-ga-context=\"talks\"\n",
    "            # Adjust the data-ga-* attributes or classes as needed to match the actual page.\n",
    "            links = soup.select('a[data-ga-context=\"talks\"][href^=\"/talks/\"]')\n",
    "            if not links:\n",
    "                logging.warning(\"No talk links found with the given selector. Check page structure.\")\n",
    "            \n",
    "            for link in links:\n",
    "                href = link.get('href')\n",
    "                if href:\n",
    "                    # Remove query parameters if present\n",
    "                    full_url = self.base_url + href.split('?')[0]\n",
    "                    if full_url not in talk_urls:\n",
    "                        talk_urls.append(full_url)\n",
    "\n",
    "        return talk_urls\n",
    "\n",
    "    def get_opening_line(self, talk_url):\n",
    "        \"\"\"\n",
    "        Scrape the transcript page for a talk and extract the first paragraph,\n",
    "        which we assume to be the opening line.\n",
    "        \"\"\"\n",
    "        transcript_url = talk_url + \"/transcript\"\n",
    "        logging.info(f\"Fetching transcript from: {transcript_url}\")\n",
    "        response = requests.get(transcript_url)\n",
    "        if response.status_code != 200:\n",
    "            logging.error(f\"Failed to fetch transcript for {talk_url}\")\n",
    "            return None\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        if not paragraphs:\n",
    "            logging.warning(f\"No transcript paragraphs found for {talk_url}\")\n",
    "            return None\n",
    "        \n",
    "        # Use the first non-empty paragraph as the opening line.\n",
    "        for p in paragraphs:\n",
    "            line = p.get_text(strip=True)\n",
    "            if line:\n",
    "                return line\n",
    "        return None\n",
    "\n",
    "    def pull_all_opening_lines(self, num_pages=1):\n",
    "        \"\"\"\n",
    "        Retrieve all opening lines from the scraped talk URLs.\n",
    "        \"\"\"\n",
    "        talk_urls = self.get_talk_urls(num_pages=num_pages)\n",
    "        logging.info(f\"Found {len(talk_urls)} talk URLs\")\n",
    "        logging.info(f\"Sample talk URLs: {talk_urls[:3]}\")\n",
    "        \n",
    "        opening_lines = []\n",
    "        for talk_url in talk_urls:\n",
    "            line = self.get_opening_line(talk_url)\n",
    "            if line:\n",
    "                opening_lines.append((talk_url, line))\n",
    "        return opening_lines\n",
    "\n",
    "\n",
    "class TEDTalkProcessor:\n",
    "    \"\"\"\n",
    "    Orchestrates the process of scraping TED talks and extracting their opening lines.\n",
    "    \"\"\"\n",
    "    def __init__(self, scraper: TEDTalkScraper):\n",
    "        self.scraper = scraper\n",
    "\n",
    "    def process(self, num_pages=1):\n",
    "        opening_lines = self.scraper.pull_all_opening_lines(num_pages=num_pages)\n",
    "        results = []\n",
    "        for url, line in opening_lines:\n",
    "            results.append({\n",
    "                'url': url,\n",
    "                'opening_line': line\n",
    "            })\n",
    "        logging.info(f\"Processed {len(results)} opening lines\")\n",
    "        logging.info(f\"Sample results: {results[:3]}\")\n",
    "        return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    scraper = TEDTalkScraper()\n",
    "    processor = TEDTalkProcessor(scraper)\n",
    "\n",
    "    # Pull data from 1 page for demonstration; adjust num_pages as needed.\n",
    "    results = processor.process(num_pages=1)\n",
    "\n",
    "    # Output the results\n",
    "    for item in results:\n",
    "        print(f\"Talk URL: {item['url']}\")\n",
    "        print(f\"Opening Line: {item['opening_line']}\")\n",
    "        print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
